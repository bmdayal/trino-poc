{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trino in c:\\python\\python312\\lib\\site-packages (0.334.0)\n",
      "Requirement already satisfied: lz4 in c:\\python\\python312\\lib\\site-packages (from trino) (4.4.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\bmday\\appdata\\roaming\\python\\python312\\site-packages (from trino) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in c:\\python\\python312\\lib\\site-packages (from trino) (2025.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\python\\python312\\lib\\site-packages (from trino) (2.32.3)\n",
      "Requirement already satisfied: tzlocal in c:\\python\\python312\\lib\\site-packages (from trino) (5.3.1)\n",
      "Requirement already satisfied: zstandard in c:\\python\\python312\\lib\\site-packages (from trino) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\python312\\lib\\site-packages (from requests>=2.31.0->trino) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python312\\lib\\site-packages (from requests>=2.31.0->trino) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\python312\\lib\\site-packages (from requests>=2.31.0->trino) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python312\\lib\\site-packages (from requests>=2.31.0->trino) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bmday\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil->trino) (1.16.0)\n",
      "Requirement already satisfied: tzdata in c:\\python\\python312\\lib\\site-packages (from tzlocal->trino) (2025.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.38.8-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: trino in c:\\python\\python312\\lib\\site-packages (0.334.0)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bmday\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting botocore<1.39.0,>=1.38.8 (from boto3)\n",
      "  Downloading botocore-1.38.8-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.13.0,>=0.12.0 (from boto3)\n",
      "  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: lz4 in c:\\python\\python312\\lib\\site-packages (from trino) (4.4.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\python\\python312\\lib\\site-packages (from trino) (2.32.3)\n",
      "Requirement already satisfied: tzlocal in c:\\python\\python312\\lib\\site-packages (from trino) (5.3.1)\n",
      "Requirement already satisfied: zstandard in c:\\python\\python312\\lib\\site-packages (from trino) (0.23.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\python\\python312\\lib\\site-packages (from botocore<1.39.0,>=1.38.8->boto3) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bmday\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\python312\\lib\\site-packages (from requests>=2.31.0->trino) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python312\\lib\\site-packages (from requests>=2.31.0->trino) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python312\\lib\\site-packages (from requests>=2.31.0->trino) (2025.1.31)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.5 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.5/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl (25.7 MB)\n",
      "   ---------------------------------------- 0.0/25.7 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 8.9/25.7 MB 42.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.1/25.7 MB 46.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.7 MB 44.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.7/25.7 MB 38.7 MB/s eta 0:00:00\n",
      "Downloading boto3-1.38.8-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.38.8-py3-none-any.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 10.0/13.5 MB 47.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 31.4 MB/s eta 0:00:00\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading numpy-2.2.5-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 10.0/12.6 MB 47.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 46.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 28.3 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: pyarrow, numpy, jmespath, pandas, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.38.8 botocore-1.38.8 jmespath-1.0.1 numpy-2.2.5 pandas-2.2.3 pyarrow-20.0.0 s3transfer-0.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyarrow boto3 trino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì• Step 2: Load and convert CSV ‚Üí Parquet (locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"spotify_dataset.csv\")\n",
    "df.to_parquet(\"spotify_dataset.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òÅÔ∏è Step 3: Upload Parquet to S3 (in a folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß± Step 4: Create Parquet table in Trino over that S3 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available catalogs:\n",
      "Query executed successfully. Result rows: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Catalog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Catalog\n",
       "0      s3\n",
       "1  system"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available schemas in s3 catalog:\n",
      "Query executed successfully. Result rows: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>information_schema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Schema\n",
       "0  information_schema"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>information_schema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Schema\n",
       "0  information_schema"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment out the next line if you don't want to upload a local file\n",
    "# upload_local_parquet_to_s3()import trino\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Connect to Trino (previously known as PrestoSQL)\n",
    "conn = trino.dbapi.connect(\n",
    "    host='localhost',  # Use your Trino host\n",
    "    port=8080,         # Default Trino port\n",
    "    user='trino',      # Your Trino user\n",
    "    catalog='s3',      # Your catalog name is s3, not hive\n",
    "    schema='default'   # Starting with default schema\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Function to execute queries and print results\n",
    "def execute_query(query, show_results=True):\n",
    "    cursor.execute(query)\n",
    "    if show_results and cursor.description:\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        results = cursor.fetchall()\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "        print(f\"Query executed successfully. Result rows: {len(df)}\")\n",
    "        if not df.empty and show_results:\n",
    "            display(df)\n",
    "        return df\n",
    "    print(\"Query executed successfully. No results to display.\")\n",
    "    return None\n",
    "\n",
    "# List available catalogs\n",
    "print(\"Available catalogs:\")\n",
    "execute_query(\"SHOW CATALOGS\")\n",
    "\n",
    "# List schemas in the s3 catalog\n",
    "print(\"\\nAvailable schemas in s3 catalog:\")\n",
    "execute_query(\"SHOW SCHEMAS FROM s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating schema: TrinoUserError(type=USER_ERROR, name=ALREADY_EXISTS, message=\"Schema already exists: 'spotify'\", query_id=20250505_012637_00006_927zz)\n",
      "Falling back to using default schema\n"
     ]
    }
   ],
   "source": [
    "# Create a new schema if it doesn't exist\n",
    "schema_name = \"spotify\"  # Your schema name \n",
    "try:\n",
    "    execute_query(f\"CREATE SCHEMA IF NOT EXISTS s3.{schema_name}\", show_results=False)\n",
    "    print(f\"\\nSchema '{schema_name}' created or already exists\")\n",
    "    \n",
    "    # Verify the schema was created\n",
    "    schemas_df = execute_query(\"SHOW SCHEMAS FROM s3\")\n",
    "    if schema_name in schemas_df[0].values:\n",
    "        print(f\"Confirmed: Schema '{schema_name}' exists in catalog 's3'\")\n",
    "    else:\n",
    "        print(f\"Warning: Schema '{schema_name}' was not found in the list of schemas\")\n",
    "        print(\"You may need manual configuration of your S3 connector to create schemas\")\n",
    "        \n",
    "        # Fall back to default schema\n",
    "        schema_name = \"default\"\n",
    "        print(f\"Falling back to using 's3.default' schema\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating schema: {e}\")\n",
    "    print(\"Falling back to using default schema\")\n",
    "    schema_name = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error switching to schema: TrinoUserError(type=USER_ERROR, name=NOT_FOUND, message=\"Schema does not exist: s3.spotify\", query_id=20250505_012949_00011_927zz)\n",
      "Please check your Trino server configuration for S3 connector\n",
      "Error creating table: TrinoQueryError(type=INTERNAL_ERROR, name=GENERIC_INTERNAL_ERROR, message=\"The bucket is in this region: ap-northeast-2. Please use this region to retry the request (Service: Amazon S3; Status Code: 301; Error Code: 301 Moved Permanently; Request ID: 1GC6BWKYHPS40T70; S3 Extended Request ID: O9KamDW8JApc5u1mh/qKs4QOlDdGDEK74gdhLPcqomuSJwVxFSmHWAIf0Hlmuvv5ci+gE+h/Emo=; Proxy: null)\", query_id=20250505_012949_00012_927zz)\n",
      "This might be due to permissions or S3 connector configuration issues\n"
     ]
    }
   ],
   "source": [
    "schema_name = 'spotify'\n",
    "try:\n",
    "    execute_query(f\"USE s3.{schema_name}\")\n",
    "    print(f\"Successfully switched to schema s3.{schema_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error switching to schema: {e}\")\n",
    "    print(\"Please check your Trino server configuration for S3 connector\")\n",
    "\n",
    "# Create the table for the Spotify dataset\n",
    "# Note: Adjust the column definitions based on your actual parquet file structure\n",
    "table_name = \"spotify_tracks123\"\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS s3.{schema_name}.{table_name} (\n",
    "    id VARCHAR,\n",
    "    name VARCHAR,\n",
    "    popularity INTEGER,\n",
    "    duration_ms BIGINT,\n",
    "    explicit BOOLEAN,\n",
    "    artists VARCHAR,\n",
    "    id_artists VARCHAR,\n",
    "    release_date VARCHAR,\n",
    "    danceability DOUBLE,\n",
    "    energy DOUBLE,\n",
    "    key INTEGER,\n",
    "    loudness DOUBLE,\n",
    "    mode INTEGER,\n",
    "    speechiness DOUBLE,\n",
    "    acousticness DOUBLE,\n",
    "    instrumentalness DOUBLE,\n",
    "    liveness DOUBLE,\n",
    "    valence DOUBLE,\n",
    "    tempo DOUBLE\n",
    ")\n",
    "WITH (\n",
    "    external_location = 's3a://spotify/spotify_dataset/',\n",
    "    format = 'PARQUET'\n",
    ")\n",
    "\"\"\"\n",
    "try:\n",
    "    execute_query(create_table_query, show_results=False)\n",
    "    print(f\"\\nTable '{table_name}' created or already exists\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating table: {e}\")\n",
    "    print(\"This might be due to permissions or S3 connector configuration issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABBA', \"She's My Kind Of Girl\", 'joy', '0.4476190476190476', 'pop', '2014', 'F Maj', '128', '-6.0', 'No', '31', '78', '56', '60', '3', '31', '7', '0']\n",
      "['ABBA', 'Andante, Andante', 'love', '0.20222222222222216', 'pop', '1980', 'A# Maj', '102', '-10.72', 'No', '59', '36', '52', '38', '2', '7', '68', '0']\n",
      "['ABBA', 'As Good As New', 'sadness', '0.3008807588075881', 'pop', '1979', 'E Maj', '139', '-5.7', 'No', '50', '78', '85', '97', '3', '8', '20', '2']\n",
      "['ABBA', 'Bang', 'joy', '0.355', 'pop', '1975', 'F Maj', '132', '-3.0', 'No', '52', '76', '50', '89', '3', '32', '3', '0']\n",
      "['ABBA', 'Bang-A-Boomerang', 'joy', '0.355', 'pop', '1975', 'F Maj', '132', '-3.0', 'No', '52', '76', '50', '89', '3', '32', '3', '0']\n"
     ]
    }
   ],
   "source": [
    "from trino.dbapi import connect\n",
    "from trino.auth import BasicAuthentication\n",
    "\n",
    "# Connect to Trino\n",
    "conn = connect(\n",
    "    host='localhost',  # or your docker host IP\n",
    "    port=8080,\n",
    "    user='admin',\n",
    "    catalog='s3',\n",
    "    schema='spotify',\n",
    "    auth=BasicAuthentication(\"admin\", \"\"),\n",
    "    http_scheme='http'  # change to 'https' if applicable\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Step 1: Create Schema (if not exists)\n",
    "cur.execute(\"CREATE SCHEMA IF NOT EXISTS s3.spotify\")\n",
    "\n",
    "# Step 2: Create External Table over CSV in S3\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS s3.spotify.spotify_dataset (\n",
    "    track_id VARCHAR,\n",
    "    track_name VARCHAR,\n",
    "    artist_name VARCHAR,\n",
    "    album_name VARCHAR,\n",
    "    duration_ms VARCHAR,\n",
    "    popularity VARCHAR,\n",
    "    danceability VARCHAR,\n",
    "    energy VARCHAR,\n",
    "    key VARCHAR,\n",
    "    loudness VARCHAR,\n",
    "    mode VARCHAR,\n",
    "    speechiness VARCHAR,\n",
    "    acousticness VARCHAR,\n",
    "    instrumentalness VARCHAR,\n",
    "    liveness VARCHAR,\n",
    "    valence VARCHAR,\n",
    "    tempo VARCHAR,\n",
    "    time_signature VARCHAR\n",
    ")\n",
    "WITH (\n",
    "    external_location = 's3a://spotify/spotify_dataset/',\n",
    "    format = 'CSV',\n",
    "    skip_header_line_count = 1\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Step 3: Query the new table\n",
    "cur.execute(\"SELECT * FROM s3.spotify.spotify_dataset LIMIT 5\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Display rows\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['playlist'], ['spotify_dataset']]\n",
      "[['ABBA', \"She's My Kind Of Girl\", 'joy', '0.4476190476190476', 'pop', '2014', 'F Maj', '128', '-6.0', 'No', '31', '78', '56', '60', '3', '31', '7', '0'], ['ABBA', 'Andante, Andante', 'love', '0.20222222222222216', 'pop', '1980', 'A# Maj', '102', '-10.72', 'No', '59', '36', '52', '38', '2', '7', '68', '0'], ['ABBA', 'As Good As New', 'sadness', '0.3008807588075881', 'pop', '1979', 'E Maj', '139', '-5.7', 'No', '50', '78', '85', '97', '3', '8', '20', '2'], ['ABBA', 'Bang', 'joy', '0.355', 'pop', '1975', 'F Maj', '132', '-3.0', 'No', '52', '76', '50', '89', '3', '32', '3', '0'], ['ABBA', 'Bang-A-Boomerang', 'joy', '0.355', 'pop', '1975', 'F Maj', '132', '-3.0', 'No', '52', '76', '50', '89', '3', '32', '3', '0']]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SHOW TABLES IN s3.spotify\")\n",
    "print(cur.fetchall())\n",
    "\n",
    "cur.execute(\"SELECT * FROM s3.spotify.spotify_dataset LIMIT 5\")\n",
    "print(cur.fetchall())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
